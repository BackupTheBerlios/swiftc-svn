\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{ngerman}
\usepackage{array}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{array}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

%opening
\title{Automatische SIMD-Code-Generierung}
\author{Roland Leißa}

\begin{document}

\thispagestyle{empty}

\maketitle
\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\tableofcontents
\thispagestyle{empty}
    %\pagenumbering{Roman}
\newpage
    \newpage
    \setcounter{page}{1}

\section{Einleitung}

In dieser Ausarbeitung wird zuerst vorgestellt, was eine SIMD-Architektur ist und wie man sie
einsetzen kann, um performanten Code zu schreiben. Dies wird dann am Beispiel X64-Architektur
\footnote{Ursprünglich hieß die Architektur AMD64. Da Intel eine ähnliche Architektur mit dem Name
EM64t eingeführt hat, wird diese Klasse von Prozessoren auch X64 oder X86\_64 genannt, um an den X86
zu erinnern. Aber auch der Name AMD64 ist noch üblich.} verdeutlicht.

Im Anschluss werden die gängigsten Techniken eingeführt, die Programmierer nutzen, um die
Geschwindigkeitvorzüge einer SIMD-Architektur auch zu erhalten. Basierend auf den gesammelten
Vor- und Nachteilen wird eine neue Technik vorgestellt.

\newpage

\section{Die SIMD-Architektur}

SIMD (Single Instruction Multiple Data) ist nach der Klassifikation von Flynn ein Rechenmodell, das
mit einer einzelnen Anweisung mehrere Daten bearbeitet. Wenn ein Befehl beispielsweise zwei Tupel
von Floats paarweise miteinander addiert und in ein Ergebnis-Tupel schreibt, ist dies eine
SIMD-Anweisung.

Typischerweise besitzt ein SIMD-fähiger Prozessor gesonderte Register mit entsprechender Breite, die
mehrere Daten parallel halten können. Zusätzlich gibt es einen Befehlssatz, der mit diesen
SIMD-Registern rechnet. Ein 64-Bit breites Register könnte beispielsweise acht Bytes, vier Words
oder zwei Doublewords bzw. zwei Floats halten. Dies ist beispielsweise in der MMX und
3DNow-Erweiterung der X86-Prozessoren der Fall. Ein gesonderter Befehlssatz erlaubt dann
Rechenoperation der Form:

\begin{eqnarray*}
    (r_1, r_2, ..., r_n)    & = & op\Bigl( (a_1, a_2, \dots, a_n), (b_1, b_2, \dots, b_n) \Bigr)\\ 
                            & = & (a_1 \ op \ b_1, a_2 \ op \ b_2, \dots, a_n \ op \ b_n)
\end{eqnarray*}

Etwas komplizierter wird es, sobald bedingter Code gebraucht wird. Dies wird realisiert, indem eine
Maske erzeugt wird und die Resultate entsprechend verknüpft:

Diesen Code

\begin{verbatim}
for i in [0, n[
    if (a[i] > 10)
        a[i] += b[i]
    else
        a[i] += c[i]
\end{verbatim}
    
schreibt man dann als:

\begin{verbatim}
mask = a > 10                       # erzeugt in jedem Element entweder 1 oder 0
a = a + mask * b + inv(mask) * c    # inv(mask) erzeugt die invertierte Maske von mask
\end{verbatim}

Alternativ, kann man auch durch geschicktes Nutzen von AND, NAND und OR die Operanden
verknüpfen, wenn der Vergleich eine Maske zurückgibt, die ein komplett gesetztes Bitmuster
im Falle von \emph{true} zurückgibt, und ein komplett gelöschtes im Falle von \emph{false}:

\begin{verbatim}
mask = a > 10
b' = AND(mask, b)
c' = NAND(mask, c)
d  = OR(b', c')
a += d
\end{verbatim}

Auf den ersten Blick scheint der Geschwindigkeitsvorzug nicht besonders zu sein, insbesondere wenn
nur zwei Daten in einem Register gehalten werden können. Wenn man davon ausgeht, dass die Bedingung
in der Hälfte der Fälle greift und die \texttt{else}-Klausel sogar fehlt, hätte man quasi nichts
gewonnen. Zu beachten ist aber, dass Code-Verzweigungen wegen Cache-Misses sehr teuer sein können.
Aus diesen Gründen versuchen optimierende Compiler Verzweigungen wegzuoptimieren, wenn es möglich
ist, oder wenigstens eine brauchbare Branchprediction zu geben, um dem Prozssor einen Hinweis zu
geben, welche Verzweigung die wahrscheinlichste ist. Mit dieser Information im Hinterkopf scheint
der obige Code doch wieder vorteilhaft zu sein, selbst wenn $n = 2$ ist.

\subsection{Die X64-Architektur}

Neben dem schon kurz erwähnten MMX oder 3DNow-Befehlen, die mittlerweile als veraltet gelten, gibt
es 128-Bit-Media-Anweisungen. Intel hat diese Befehle unter dem Namen SSE eingeführt.  Mittlerweile
gibt es schon mehrere Erweiterung basierend auf dem ersten SSE. Und auch 256-Bit-Media-Anweisungen
sind schon von Intel in Arbeit. Die Beispiele in dieser Ausarbeitung werden sich auf SSE
beschränken, um die Problematiken der Beispiele konsistent zu halten.

Für die X64-Architektur gibt es bereits reichlich Literatur. Deshalb werden an dieser Stelle nur die
wichtigsten Eigenschaften kurz aufgezählt. Der X64-Prozessor hat im 64-Bit Modus 16 unabhängige
128-Bit breite XMM-Register: \texttt{xmm0} bis \texttt{xmm15}. Folgende Datentypen lassen sich in
ein Register laden:

\begin{itemize}
    \item 16 signed oder unsigned Bytes
    \item Acht signed oder unsigned Words
    \item Vier signed oder unsigned Doublewords
    \item Zwei signed oder unsigned Quadwords
    \item Vier Floats
    \item Zwei Doubles
\end{itemize}

Je nachdem, wie man die Register verwenden will, verwendet man unterschiedliche Befehle. Eine
parallele Multiplikation der Form \texttt{xmm0 *= xmm1} von vier Floats lässt sich in \texttt{mulps
\%xmm1, \%xmm0} (multiply packed singles) kodieren. Eine Parallele Addition von 16 sigend oder
unsigned Bytes der Form \texttt{xmm0 += xmm1} geschieht mit: \texttt{paddb \%xmm1, \%xmm0} (packed
add bytes). 

Auch zu der bereits oben erwähnten Branchelimination gibt es entsprechende Befehle. Das obige
Code-Fragment sieht mit vier Floats folgendermaßen aus:

\begin{verbatim}
// Registerzuteilung:
// a    -> xmm0
// b    -> xmm1
// c    -> xmm2
// b'   -> xmm3
// c'   -> xmm4
// d    -> xmm5
// mask -> xmm6
// m10 ist eine Stelle im Speicher, die die Konstante 10 hält

movaps   %xmm0, %xmm6; a -> mask
cmpnleps m10,   %xmm1; mask > 10 -> mask   (compare not less equal packed singles)
movaps   %xmm1, %xmm3; b -> b'
andps    %xmm6, %xmm3; AND(mask, b) -> b'  (and packed singles) 
movaps   %xmm2, %xmm4; c -> c'
andnps   %xmm6, %xmm4; NAND(mask, c) -> c' (and not packed singles)
movaps   %xmm4, %xmm5; c' -> d
orps     %xmm3, %xmm5; OR(b', c') -> d     (or packed singles)
addps    %xmm5, %xmm0; a += d              (add packed singles)
\end{verbatim}

Zu beachten ist, dass in diesem Beispiel die Registerzuteilung nicht optimal ist. Auf diese Weise
lässt sich das Beispiel aber besser nachvollziehen. Einige Kopien können wegoptimiert werden
und insgesamt würden weniger Register gebraucht werden.

Als zusätzliche Hürde bleibt zu erwähnen, dass es bei den SSE-Befehlen zwei Arten von
Speicherzugriffen gibt: aligned und unaligned. Weiß der Programmierer, dass der Speicher, aus dem
geladen werden soll, bei einer Adresse anfängt, die durch 16 teilbar ist, können schnellere aligned
Moves benutzt werden (\texttt{movaps}) gegenüber den langsameren unaligned Moves (\texttt{movups}).

\newpage
\section{SIMD-Programmierung}

Im folgenden werden nun einige Techniken präsentiert, um prinzipiell SIMD-Befehle nutzen zu können.
Dabei konzentrieren sich die Beschreibungen beispielhaft auf die SSE-Befehle für die parallele
Verarbeitung von vier Floats (packed singles). 

\subsection{Arrays atomarer Datentypen}

Triviale Beispiele sind Schleifen über Arrays atomarer Datentypen, in denen mit den Arrays
gerechnet wird:

\begin{verbatim}
float* a, *b, *c; // Arrays der Größe SIZE
// ...
for (size_t i = 0; i < SIZE; ++i)
    a[i] = b[i] + c[i];
\end{verbatim}

Es ist sofort ersichtlich, dass sich dieser Code leicht umformen lässt, so dass die
\texttt{addps}-Anweisung (add packed singles) genutzt werden kann. Sind weiterhin die
Anfangsadressen von \texttt{a}, \texttt{b} und \texttt{c} aligned, können aligned Moves genutzt
werden, um die Array-Inhalte in die Register zu laden. Man erreicht einen Speedup von vier. Ggf.
müssen die Arrays etwas größer gemacht werden, damit beim Lesen des letzten Elementes keine
Speicherzugriffsfehler auftreten.

\subsection{Array of Structures}

Arrays von atomaren Datentypen treten in der Praxis eher selten auf, insbesondere dann, wenn eine
modulare Programmierung vorliegt. Als laufendes Beispiel wird nun folgender C++ Code betrachtet:

\begin{verbatim}
struct Vec3 {
    float x;
    float y;
    float z;

    Vec3 operator + (const Vec3& v) {
        Vec3 result;
        result.x = x + v1.x;
        result.y = y + v1.y;
        result.z = z + v1.z;
        return result;
    }

    static Vec3 cross (Vec3 v1, Vec3 v2)
        Vec3 result;
        result.x = v1.y * v2.z - v1.z * v2.y
        result.y = v1.z * v2.x - v1.x * v2.y
        result.z = v1.x * v2.y - v1.y * v2.x
        return result;
    end
};

void someFunction() {
    Vec3 *a, *b, *c; // Arrays von Vec3, die später jeweils SIZE-viele Elemente haben
    //...
    for (size_t i = 0; i < SIZE; ++i)
        a[i] = b[i] + c[i];
    //...
    for (size_t i = 0; i < SIZE; ++i)
        a[i] = Vec3::cross(b[i], c[i]);
}
\end{verbatim}

Die erste Auffälligkeit ist, dass ein Array von Vec3 ein ungünstiges Speicherlayout hat:

\begin{verbatim}
x0 y0 z0 x1 y1 z1 x2 y2 z2 x3 y3 z3 ... xn-1 yn-1 zn-1
\end{verbatim}

Möchte ein Programmierer nun Gebrauch von der \texttt{addps}-Instruktion machen, muss er einen
unaligned load durchführen, da nur höchstens jedes vierte Vec3 aligned ist. Danach können die Vec3
parallel addiert werden, wobei aber ein Slot nicht gebraucht wird. Man hätte also grob einen Speedup
von 3. Unschön ist der unaligned Speicherzugriff, der die Performance drastisch senkt. Zu erwähnen
bleibt, dass das Array eventuell um ein Float größer alloziert werde muss, damit es beim lesen des
letzten Elementes nicht zu einem Speicherzugriffsfehler kommt.

Durch Hinzufügen eines zusätzliches Dummy-Attributs und entsprechender Speicherausrichtung können
ggf. aligned Moves benutzt werden:

\begin{verbatim}
struct Vec3 {
    float x;
    float y;
    float z;
    float dummy;
};
\end{verbatim}

Es ergibt sich folgendes Speicherlayout für entsprechende Arrays:

\begin{verbatim}
x0 y0 z0 d0  x1 y1 z1 d1  x2 y2 z2 d2  x3 y3 z3 d3 ... xn-1 yn-1 zn-1 dn-1
\end{verbatim}

Wenn der Programmierer nun dafür sorgt, dass die Anfangs-Adressen des Arrays aligned sind, können
aligned Moves verwendet werden. Allerdings wird hier 25\% des allozierten Speichers verschwendet und
nach wie vor erreicht man höchstens einen Speedup von 3, da immer ein Element der vier Floats
ignoriert wird. Diese Technik wurde z.B. in der Quake-Engine verwendet.

Diese Speicherlayouts nennt man auch AoS (Array of Structures). Für das Kreuzprodukt wird man allerdings
kaum eine Möglichkeit zur Parallelität finden.

\subsection{Structure of Arrays}

Eine effizientere Möglichkeit bieten Structure of Arrays (SoA):

\begin{verbatim}
struct Vec3Array {
    float x[SIZE];
    float y[SIZE];
    float z[SIZE];
};
\end{verbatim}

Folgendes Speicherlayout ergibt sich:

\begin{verbatim}
x0 x1 x2 x3 ... xn-1  y0 y1 y2 y3 ... yn-1  z0 z1 z2 z3 ... zn-1
\end{verbatim}

Sorgt der Programmierer wieder dafür, dass eine Instanz des \texttt{Vec3Array}s aligned ist, lassen sich vier
x-Werte, vier y-Werte und vier z-Werte parallel aus dem Speicher laden und parallel mit anderen
entsprechenden Datenstrukturen verknüpfen. Alle vier Slots eines XMM-Register werden jetzt
gebraucht, ohne dass ein Slot brach liegt. Wenn \texttt{SIZE} nicht durch vier teilbar ist, muss es
auf den nächsten Faktor von vier erhöht werden, damit es gegen Ende der Schleife nicht zu
Speicherfehlern kommt. Ggf. müssen AoS erst in SoA konvertiert werden. AMD und Intel empfehlen dies
bei großen Arrays. 

Das Kreuzprodukt kann hier auch parallelisiert werden. Dies geschieht analog zur Vektoraddition.

Von dem Overhead abgesehen, der ensteht AoS in SoA und umgekehrt zu konvertieren, hat auch diese
Techniken einige Nachteile: Bei großen Arrays erhöht sich die Wahrscheinlichkeit von Cache-Misses, da
die Werte, die aus dem Speicher geladen werden, immer weiter auseinander liegen, desto größer die
Arrays werden. Bei wirklich großen Arrays spielen schließlich auch Effekte wie Paging eine Rolle,
die die Performance drastisch senken.

\subsection{Array of Structures of Arrays}

Als letzte Alternative gibt es einen Hybrid aus beiden Ansätzen:

\begin{verbatim}
struct Vec3_4 {
    float x[4];
    float y[4];
    float z[4];
};
\end{verbatim}

Ein Array von \texttt{Vec3\_4} mit $SIZE/4$ Elementen hat nun dieses Speicherlayout:

\begin{verbatim}
x0 x1 x2 x3  y0 y1 y2 y3  z0 z1 z2 z3  x4 x5 x5 x7  y4 y5 y6 y7  z4 z5 z6 z7 ... 
    xn-4 xn-3 xn-2 xn-1  yn-4 yn-3 yn-2 yn-1  zn-4 zn-3 zn-2 zn-1
\end{verbatim}

Da dem Autor kein gängiger Name für dieses Speicherlayout bekannt, wird es im folgenden Array of
Structures of Arrays (AoSoA) genannt.

Für die Vektoraddition iteriert man über die Arrays mit $SIZE/4$ Elementen und lädt parallel 
die vier x-Werte in die Register und addiert. Genauso verfährt man mit den y- und z-Werten.
Das optimierte Kreuzprodukt implementiert man ähnlich.

\newpage
\section{Aktuelle Programmierer-Techniken für SIMD-Code}

Nach den Überlegungen aus dem letzten Absatz, gilt es nun die Entwicklunswerkzeuge so einzusetzen,
dass der gewünschte Code erzeugt wird. Unter diesem Gesichtspunkt sind weitere Punkte
wünschenswert:

\begin{description}
    \item[Modularität] Eine möglichst modulare Programmierung sollte möglich sein: Eine einmal definierte
    Operation sollte nicht für Spezialfälle (wie bei großen Arrays) neu programmiert werden, um
    einen Speedup zu erreichen.

    \item[Portabilität] Der Code sollte portabel sein: Wenn sich der Programmierer schon die Mühe
    gemacht hat, Code für SIMD-Architekturen zu optimieren, sollte dieser Code auch optimiert auf
    anderen SIMD-fähigen Prozessoren laufen.

    \item[High-Level-Programmierung] Dem Programmierer sollte so viel Arbeit wie möglich abgenommen werden: Zum einen heißt
    dies, dass nötige Konvertierungen möglichst automatisch vom Compiler durchgeführt werden
    sollten, und zum anderen, dass sich der Programmierer mit so wenigen Low-Level-Details
    beschäftigen sollte, wie nötig.

\end{description}

\subsection{Assembler-Ebene}

Am sichersten ist es natürlich den Assembler-Code von Hand zu schreiben. In diesem Fall kann sich
der Programmierer sicher sein, dass der gewünschte Code erzeugt wird. Hier gibt es prinzipiell drei
Möglichkeiten:

\begin{description}

    \item[Der Standalone-Assembler] Der Standalone-Assembler ist der klassische Assembler, der
    Assembler-Code in Maschinencode übersetzt. Gute Assembler haben mächtige Makro-Funktionen, mit
    denen man schon kleine Programmiersprachen auf Makro-Basis bauen kann. In diesem Szenario
    schreibt der Programmierer optimierte Unterprogramme, die dann schließlich in die Hochsprache
    eingebunden werden. Problematisch ist, dass besonders kleine Unterprogramme einen ziemlichen
    großen Overhead beim Prozeduraufruf erzeugen können, was evtl. wieder viel von der gewonnen
    Performance schluckt. Bei Unterprogrammen, die lange Schleifen durchführen, ist dies zu
    vernachlässigen.

    \item[Der Inline-Assembler] Sprachen wie C oder C++ unterstützten das direkte Einbinden von
    Assembler-Code.  Der Overhead des Prozeduraufrufs verschwindet hier. Da der Compiler allerdings
    nicht sicher sein kann, welche Register gebraucht werden, kann vor und nach dem
    Inline-Assembler-Code ggf. ein gewisser Overhead enstehen. Die erweiterte
    Inline-Assembler-Syntax des GNU-Compilers umgeht dieses Problem, erfordert aber noch mehr
    Arbeit des Programmierers. Von dieser Technik wird beispielsweise im Linux-Kernel Gebrauch
    gemacht.

    \item[Compiler-Intrinsics] Compiler-Intrinsics sind fest im Compiler eingebaute Funktionen, die
    Assembler-Befehle in der Hochsprache kapseln. Der Programmierer kann hier die Registerzuteilung
    dem Compiler überlassen und es ensteht kein weiter Overhead bei der Benutzung dieser speziellen
    Funktionen. Diese Variante ist in der Regel die performanteste.  Intrinsic-Code, der für SSE
    geschrieben wurde, lässt sich sogar sowohl für X86 als auch für X64 kompilieren, was sogar einen
    kleinen Grad an Portabilität zulässt.

\end{description}

Die generellen Vor- und Nachteile von Assembler sind bekannt und sollen an dieser Stelle nicht noch
einmal wiederholt werden. Zu beobachten ist allerdings, dass alle drei wünschenswerte Kriterien
nicht erfüllt werden. Die Speicherausrichtung ist hier noch ein weiteres Problem. Die Aussagen über
die Speicherausrichtung im nächsten Abschnitt gelten auch hier.

\subsection{Der Auto-Vektorisierer}

Ein Auto-Vektorisierer ist eine Optimierung, die in modernen Compilern eingesetzt wird, um
automatisch SIMD-Code zu generieren (vektorisieren). Der Intel-Compiler (\texttt{icc}) und der
GNU-Compiler (\texttt{gcc}) unterstützen dies zum Beispiel. 

Es ist allerdings zum Teil sehr schwer den Compiler auch zu überreden, eine Schleife entsprechend zu
transformieren. Prinzipiell funktioniert das nur bei Schleifen über Arrays mit atomaren Datentypen.
Es gibt zusätzliche Compiler-Flags, um das Optimieren kritischer Schleifen zu debuggen.
Typischerweise endet das in einem Trial-And-Error-Ansatz des Programmierers, die Schleife so lange
umzuformulieren, bis der Compiler die Schleife in einer Form vorliegen hat, die er dann
vektorisieren kann. Weiter müssen die Speicherbereiche in der Regel mit \texttt{restrict}, ein
Qualifizierer aus dem C99-Standard, qualifiziert sein, der garantiert, dass sich die
Speicherbereiche nicht überlappen.

Insbesondere die Speicherausrichtung ist ein großes Problem. Es gibt Compiler spezifische
Erweiterungen, um Datentypen eine Ausrichtung zu geben. Die Ausrichtung ist bei dynamisch
angefordertem Speicher allerdings nicht mehr garantiert. Abhilfe schaffen in dieser Beziehung:
\texttt{posix\_memalign}, andere Compiler spezifische Erweiterungen oder Pointer-Tricks. In C++ kann
man \texttt{new}, \texttt{delete}, Array-\texttt{new} und Array-\texttt{delete} entsprechend
überladen, um die Handhabung zu vereinfachen. Selbst wenn diese Vorkehrungen getroffen sind, sind
teilweise noch Tricks nötig, damit der Compiler wirklich aligend Moves nutzt.

Wie man sieht, ist der Auto-Vektorisierer zwar eine nützliche Optimierung, auf die man sich aber in wirklich
kritischen Code-Teilen nicht verlassen kann: Im Zweifelsfall, muss der Programmierer doch zurück auf 
Assembler-Ebene gehen.

Von den wünschenswerten Kriterien wird hier immerhin die \emph{Portabilität} erreicht. Sobald
Datenstrukturen benötigt werden, die über Arrays von atomaren Datentypen hinausgehen, ist der
Programmierer wieder auf andere Techniken angewiesen.

\subsection{Eingebaute SIMD-Datentypen}

Programmiersprachen wie OpenCL, GLSL und andere Shadersprachen haben eingebaute SIMD-Datentypen.
Viele C- und C++-Compiler haben solche Typen als Erweiterung. Die Typen sind gewöhnlich Vektoren von
atomaren Datentypen der Größe 2, 4, 8 oder 16. Alle gängigen Rechenoperationen sind verfügbar und
werden elementweise ausgeführt. Die Übersetzung in SIMD-Maschinenbefehle ist sehr leicht.  Dem
Programmierer wird allerdings eine Menge Arbeitet zu gemutet, da er alle Optimierungen selbst
schreiben muss. Da die Größe der Vektoren fest gesetzt werden, kann dies -- je nach Zielmaschine --
nicht optimal sein: Ein Vektor von vier Floats ist für SSE-fähige Prozessoren vorteilhaft. Wenn aber
nur 3DNow zur Verfügung steht, müssen die vier Floats immer je in zwei MMX-Register geladen werden,
da die MMX-Register nur 64 Bit breit sind. Ein Vektor von zwei Floats wäre in diesem Fall
vorteilhafter gewesen.

Ansonsten ist diese Technik sehr \emph{portabel}. \emph{Modularität} wird hier allerdings nicht
erreicht und dem Programmierer wird viel \emph{Low-Level} Handarbeit zugemutet.


\subsection{Aktuelle Sprachunterstützungen}

Sprachen wie MatLab/Octave oder D verfolgen den Ansatz, dass man mit Arrays rechnen kann wie mit
atomaren Datentypen:

\begin{eqnarray*}
    (r_1, r_2, ..., r_n)    & = & op\Bigl( (a_1, a_2, \dots, a_n), (b_1, b_2, \dots, b_n) \Bigr)\\ 
                            & = & (a_1 \ op \ b_1, a_2 \ op \ b_2, \dots, a_n \ op \ b_n)
\end{eqnarray*}

Oder ein atomarer Datentyp wird als Operand für alle Operationen verwendet:

\begin{eqnarray*}
    (r_1, r_2, ..., r_n)    & = & op\Bigl( a, (b_1, b_2, \dots, b_n) \Bigr)\\ 
                            & = & (a \ op \ b_1, a \ op \ b_2, \dots, a \ op \ b_n)
\end{eqnarray*}

Dass sich dies einfach vektorisieren lässt, liegt auf der Hand. Verzweigungen müssen allerdings
manuell eliminiert werden. Dieses Verfahren erfüllt zwar alle wünschenswerten Kriterien, aber bei
Datenstrukturen, die über Arrays von atomaren Datentypen hinausgehen, muss auch hier der
Programmierer andere Techniken verwenden.

\subsection{Benutzung von Bibliotheken}

Die einfachste Möglichkeit ist vielleicht die Verwendung von optimierten Bibliotheken. Man wird aber
nicht für jedes erdenkliche Problem optimierte Bibliotheken finden. Schließlich müssen auch die
Bibliotheken implementiert werden, so dass dies eigentlich nur als eine Verschleierung der
eigentlichen Problematik angesehen werden kann.

\subsection{Zusammenfassung}

Es wurde gezeigt, dass es keine Programmiertechnik gibt, die alle drei wünschenswerten Kriterien
erfüllt und dabei mit komplexeren Datenstrukturen umgehen kann. Eine neue Technik, die diese
Anforderungen erfüllt, ist also wünschenswert.

\newpage
\section{Sprachgestützte SIMD-Code-Generierung}

Ausgehend von der Technik aktueller Sprachunterstützung, wird eine neue Technik vorgestellt, die das Problem
elegant lösen kann. Die Philosophie hierbei ist, dass mit ein wenig Aufwand des Programmierers, bestimmte
Sprachkonstrukte verwendet werden können, die automatisch die gewünschten Resultate erzeugen.

Neben typischen Sprachelementen wie Structs und Arrays muss es einen \emph{SIMD-Container} geben.
Dieser SIMD-Container erzeugt automatisch das Speicherlayout eines AoSoA. Routinen zur
Konvertierung von einem SIMD-Container zu einem Array und umgekehrt müssen auch bereit gestellt
werden.

Wenn nun bestimmte Operationen auf gewissen Typen laufen, sollte es einem Compiler möglich sein,
eine zweite Version dieser Operation zu erzeugen, die auch mit SIMD-Containern umgehen kann.

Der folgende \texttt{swift}-Code zeigt, wie so etwas aussehen kann:


\begin{verbatim}
class Vec3
    real x
    real y
    real z

    # das simd Präfix sagt dem Compiler, dass er eine zweite SIMD-Version bauen soll
    simd operator + (Vec3 v1, Vec3 v2) -> Vec3 result
        result.x = v1.x + v2.x
        result.y = v1.y + v2.y
        result.z = v1.z + v2.z
    end

    simd routine cross (Vec3 v1, Vec3 v2) -> Vec3 result
        result.x = v1.y * v2.z - v1.z * v2.y
        result.y = v1.z * v2.x - v1.x * v2.y
        result.z = v1.x * v2.y - v1.y * v2.x
    end

    routine foo(Vec3 v)
        # ...
    end
end

class Foo
#...
   routine bar()
        index SIZE = 16000000
        array{Vec3} foobar(SIZE)                # ein traditionelles Array der Größe SIZE
        simd{Vec3} v1(SIZE), v2(SIZE), v3(SIZE) # SIMD-Container der Größe SIZE
        # ...

        v1 = v2 + v3             # SIMD-Vektoraddition über alle Elemente
        simd[,]:   v1 = v2 + v3  # dito
        simd[5,]:  v1 = v2 + v3  # SIMD-Vektoraddition über die Elemente 5 bis SIZE-1
        simd[,5]:  v1 = v2 + v3  # SIMD-Vektoraddition über die Elemente 0 bis 4
        simd[5,9]: v1 = v2 + v3  # SIMD-Vektoraddition über die Elemente 5 bis 8
        # ...

        # und das gleich mit cross
        v1 = Vec3.cross(v2, v3)
        simd[,]:   v1 = Vec3.cross(v2, v3)
        simd[5,]:  v1 = Vec3.cross(v2, v3)
        simd[,5]:  v1 = Vec3.cross(v2, v3)
        simd[5,9]: v1 = Vec3.cross(v2, v3)
        # ...

        simd[3, 20]: v1.foo() # Fehler: keine SIMD-Version deklariert

        foobar = v1.toArray() # Konvertierung simd{Vec3} -> array{Vec3}
        v2 = foobar.toSimd()  # Konvertierung array{Vec3} -> simd{Vec3}
   end
end
\end{verbatim}

Der Compiler erzeugt hier automatisch eine zweite Version des +-Operators und der
\texttt{cross}-Routine, die Parameter in einem SIMD-Kontext erwarten.

Dieser Code erfüllt nun alle Anforderungen. Die folgenden Abschnitten behandeln, welche
Voraussetzungen erfüllt werden müssen, damit eine Transformation einer Routine möglich ist und wie
dies bewerkstelligt wird.

Da SIMD-Container atomarer Datentypen und Arrays atomarer Datentypen das gleiche Speicherlayout
haben, werden diese Typen für allen nachfolgenden Betrachtungen als identisch behandelt.

\subsection{Programmiermodell von SIMD-Anweisungen}

Aufgrund der angestrebten Parallelität ändert sich das Programmiermodell. Solange Funktionen
keine Seiteneffekte haben wie zum Beispiel I/O-Operationen, ist das Resultat identisch mit
einer linearen Ausführung. Wenn Seiteneffekte auftreten, muss der Programmierer mit einigen
ungewohnten Ausführreihenfolgen rechnen. 

\subsection{Voraussetzungen einer SIMD-Transformation}

Für die Aggregatstypen eines Typen, der SIMD-Methoden nutzt und/oder innerhalb eines
SIMD-Containers verwendet wird, gelten folgende Einschränkungen:

\begin{itemize}

    \item Ist der betrachtete Aggregatstyp kein atomarer Typ, so wende die Einschränkungen rekursiv
    auf dessen Aggregatstypen an.

    \item Der betrachtete Aggregatstyp darf kein Zeiger sein.

    \item \texttt{sizeof(T)} muss für alle verwendeten atomaren Aggregatstypen \texttt{T} gleich
    sein oder der Typ ist ein Boolean. 

\end{itemize}

Diese Typen, die diese Eigenschaft erfüllen, werden im folgendem \emph{homogen} genannt. Die einheitliche
Größe der atomaren Typen heißt \emph{SIMD-Breite}.

Für die Parameter- bzw Rückgabetypen und die Typen aller lokalen Variablen einer SIMD-Methode zu
einem Typen \texttt{T} gelten folgende Einschränkungen:

\begin{itemize}

    \item Ist der Typ kein atomarer Typ, so wende diese Einschränkungen rekursiv auf dessen 
    Aggregatstypen an.

    \item Der betrachtete darf kein Zeiger sein.

    \item Ist der betrachtete Typ \texttt{U} atomar, so muss \texttt{sizeof(U)} identisch sein mit
    der SIMD-Breite von \texttt{T}, oder \texttt{U} ist ein Boolean.

\end{itemize}

Insbesondere erfüllt \texttt{T} immer diese Eigenschaften. Diese Einschränkungen gelten auch für
alle Parameter- und Rückgabetypen von Funktionen, die innerhalb der Methode benutzt werden. Außerdem
müssen solche benutzten Funktionen ebenfalls als \texttt{simd} deklariert sein.

Eine \emph{SIMD-Anweisung} besteht aus einem Präfix mit Indices, die angeben, auf welche Elemente
der beteiligten SIMD-Container sich die Operation bezieht.

Bei einer SIMD-Anweisung muss jeder Eingabetyp entweder mit dem entsprechendem Parametertyp in der
entsprechenden Methode übereinstimmen, oder es ist ein SIMD-Containers des Typs. Weiter muss
wenigstens ein Eingabe- oder Ausgabetyp ein SIMD-Container sein.

\subsection{Lineare Programm-Transformationen}

Solange das Programm keine Verzweigungen enthält, müssen lediglich die vorkommenden Variablen und
Konstanten in SIMD-Variablen/Konstanten transformiert werden. Die $SIMD-Breite$ kann nun als bekannt
und berechnet vorausgesetzt werden.

Eine \emph{SIMD-Variable} bzw. eine \emph{SIMD-Konstante} ist eine Variable oder Konstante eines
\emph{SIMD-Typen}. Der SIMD-Typ eines Typen \texttt{T} wird wie folgt bestimmt:

\begin{itemize}

    \item Ist \texttt{T} ein Boolean, so ist der SIMD-Typ ein Vektor mit $SIMD-Breite$ vielen Feldern.
    Ist ein Feld komplett gesetzt, wird es als \texttt{TRUE} interpretiert. Ist ein Feld komplett
    gelöscht, wird es als \texttt{FALSE} interpretiert. Andere Bitmuster sind nicht zulässig.

    \item Ist \texttt{T} ein anderer atomarer Typ, so ist der SIMD-Typ ein Vektor vom Typ \texttt{T} mit
    $SIMD-Breite$ vielen Feldern.

    \item Ist \texttt{T} kein atomarer Typ, so ist der SIMD-Typ ein SIMD-Container vom Typ
    \texttt{T}. Parameter- und Rückgabetypen, haben keine bestimmte Größe, jedoch mindestens
    $SIMD-Breite$ viele Elemente. Lokal verwendete Typen, werden in einen SIMD-Container der Größe
    $SIMD-Breite$ transformiert. 

\end{itemize}

Konstanten werden einfach zur Compilezeit in jedes Element der entsprechenden SIMD-Konstante
kopiert. Alle gängigen Rechenoperation für atomare Typen, sind auch für SIMD-Typen definiert
und werden elementweise durchgeführt. In der Notation wird im folgendem kein Unterschied gemacht, 
da aus dem Zusammenhang klar ist, ob atomare oder SIMD-Operationen gemeint sind.

Die Anweisung $a = b + 10.0$ meint also -- wenn $a$ und $b$ Floats sind -- eine herkömmliche
Float-Addition. Sind $a$ und $b$ hingegen SIMD-Variablen und ist $10.0$ eine SIMD-Konstante, so
meint die Anweisung eine parallele Float-Addition der Form: $(a_1, a_2, \dots, a_n) = (b_1 + 10.0,
b_2 + 10.0, \dots, b_n + 10.0)$. Dabei ist $n$ identisch der $SIMD-Breite$.

Besondere Aufmerksam verdienen Anweisungen, die einen Boolean zurückgeben, wie Vergleiche. Da Booleans
entsprechend transformiert werden, enthält nun jedes Element des Ergebnis in Form eines gesetzten
oder gelöschten Bitfeldes wie oben definiert.

\subsection{Transformation von Verzweigungen}

Die Code-Transformationen in den nächsten Abschnitten gehen von einer Zwischendarstellung in
SSA-Form (Static Single Assignment Form) aus. Eine gute Einführung findet sich beispielsweise in der
Wikipedia: 

\texttt{http://en.wikipedia.org/wiki/Static\_single\_assignment\_form}

Solange der Kontrollfluss keine Schleifen (Zykel) enthält, lassen sich Verzweigungen 
relativ einfach transformieren:

\begin{itemize}

    \item Finde für jede $\Phi$-Funktion, die eine SIMD-Variable $s = \Phi(s_i, s_e)$ definiert, den
    direkten Dominator $D$. Das ist die Stelle, wo der Kontrollfluss sich aufteilt. $s_i$ sei der
    Name aus dem If-Block, $s_e$ der aus dem Else-Block.

    \item Stelle den Kontrollfluss so um, dass er wieder linear wird, indem erst der If-Block ausgeführt wird
    und anschließend der Else-Block. 
    
    \item Ersetze die IF-Anweisung durch $mask = IfExpr$.

    \item Ersetze die $\Phi$-Funktionen durch $s = OR\Bigl( AND(mask, s_i), NAND(mask, s_e)\Bigr)$

\end{itemize}

Selbst wenn Zykel enthalten sind, können If-Else-Anweisungen auf diese Weise transformiert werden,
solange ein If-Else-Block weder einen Zykel verursacht, noch einen Zykel aufbricht.

Dieses Beispiel zeigt einen If-Else-Block:

\begin{verbatim}
a0 = ...
b0 = ...
c0 = ...
...
if a0 > 10 
    a1 = a0 + 5
    c1 = c0 + a1
else
    a2 = a0 * b0
end
    a3 = phi(a1, a2)
    c1 = phi(c1, c0)
    ...
    ... = c1
    ... = a3
\end{verbatim}

Der Algorithmus transformiert das Programm in diesen linearen Ablauf:

\begin{verbatim}
a0 = ...
b0 = ...
c0 = ...
...
mask =  a0 > 10                          # Maske erzeugen, anstatt der If-Anweisung
a1 = a0 + 5                              # der If-Block
c1 = c0 + a1                             # der If-Block
a2 = a0 * b0                             # der Else-Block
a3 = OR( AND(mask, a1), NAND(mask, a2) ) # transformierte Phi-Funktion
c1 = OR( AND(mask, c1), NAND(mask, c0) ) # transformierte Phi-Funktion
...
... = c1
... = a3
\end{verbatim}

\subsection{Transformation von Schleifen}

Zuerst werden innerhalb von Schleifen alle If-Else-Anweisungen, die keine Abbruchbedingung oder
Fortsetzungsbedingung (\texttt{continue}-Anweisung) der Schleife darstellen, eliminiert. Die übrigen
If-Else-Anweisungen werden klassifiziert: Entweder ist eine If-Else-Anweisung eine Abbruchbedingung,
dann heißt diese Anweisung Abbruchverzweigung. Der Grundblock, der die Schleife weiter ausführt,
heißt Schleifenblock. Der Grundblock, der den Sprung zum Schleifenausstieg enthält, heißt
Abbruchblock. Oder eine If-Else-Anweisung ist eine Fortsetzungsbedingung. In diesem Fall heißt die
Anweisung Fortsetzungsverzweigung. Der Grundblock, der hier Schleife weiter ausführt, heißt auch
Schleifenblock. Der Grundblock, der den Sprung zum Schleifenkopf enthält, heißt Fortsetzungsblock.
Eine Abbruchverzweigung, die die Schleife dominiert in dem Block $D$, gehört ebenfalls mit zur
Schleife. Da die Schleife nur noch Abbruchverzweigungen und Fortsetzungsverzweigungen beinhaltet,
dominiert jede If-Else-Anweisunge die unteren.

Folgender Algorithmus, transformiert nun eine Schleife:

\begin{itemize}

    \item Schreibe jede If-Else-Anweisung so um, dass sie im True-Fall zum Schleifenblock führt.

    \item Füge in $D$ für jede Abbruchverzweigung $A_i$ eine Anweisung $mask_{Ai} = true$ ein.

    \item Füge in $D$ für jede Fortsetzungsverzweigung $F_i$ eine Anweisung $mask_{Fi} = true$ ein.

    \item Maskiere alle Operationen innerhalb der Schleife mit allen $mask_{Xi}$ der dominierenden
    If-Else-Anweisungen $X_i$.

    \item Änder den Kontrollfluss so, dass alle Fortsetzungsblöcke der Fortsetzungsverzweigungen
    $F_i$ am Schleifenende nacheinander ausgeführt werden und maskiere in diesen Blöcken alle
    Operationen mit $not(mask_{Fi})$ und den anderen dominierenden Masken. Dann wird erst der Sprung zum
    Schleifenkopf durchgeführt.

    \item Änder den Kontrollfluss so, dass alle Abbruchblöcke der Abbruchverzweigungen
    $A_i$ bei Terminierung der Schleife nacheinander ausgeführt werden und maskiere in diesen Blöcken alle
    Operationen mit $not(mask_{Ai})$ und den anderen dominierenden Masken. Dann wird erst der Sprung zum
    Block nach der Schleife durchgeführt.

    \item Schreibe jede Fortsetzungsverzweigung $F_i$ um in die Anweisung $mask_{Fi} = AND(mask_{Fi}, if-Expr)$.

    \item Schreibe jede Abbruchverzweigung $A_i$ um in die Befehlsfolge
    \begin{eqnarray*}
        mask_{Ai} & = & AND(mask_{Ai}, if-Expr) \\
        if\ mask_{Ai} & = & (false, \dots, false) \dots
    \end{eqnarray*}

    \item Führe eine SSA-Wiederherstellung durch.

\end{itemize}

Im Falle von fehlenden Blöcken und trivialen Blöcken, die nur einen Sprung enthalten, lässt sich das Schema etwas
optimieren.

Diese Schleife

\begin{verbatim}
L1:
    a0 = ...
    b0 = ...
L2:
    a1 = phi(a0, a2)
    b1 = phi(b0, b2)
    a2 = a1 + 1
    b2 = b1 * a1
    if a2 > 10
        goto L3
    goto L2
L3: 
    ...
\end{verbatim}

wird dann entsprechend in diesen Ablauf transformiert:

\begin{verbatim}
L1:
    a0 = ...
    b0 = ...
    mask0 = (true, true, ..., true)         # mask initialisieren
L2:
    a1 = phi(a0, a3)                        # ersetze a2 bzw. b2 mit neuer Definition, 
    b1 = phi(b0, b3)                        # bei der mask verwendet wurde.
    mask1 = phi(mask0, mask1)               # phi-Funktion für mask
    a2 = a1 + 1
    b2 = b1 * a1
    a3 = AND(mask, a2)                      # mask anwenden
    b3 = AND(mask, b2)                      # dito
    mask = a1 > 10
    if mask != (false, false, ..., false)   # nur abbrechen, wenn alle Bedingungen greifen
        goto L3
    goto L2
L3: 
    ...
\end{verbatim}

%\section{Inhomegene Datentypen}

%Prinzipiell, funktionieren die vorgestellten Techniken auch mit inhomogenen Datentypen. Dies
%ist zum einen nicht mehr ganz so performant, da Konvertierungen an vielen Stellen nötig sind und
%der Registerdruck wächst, und zum anderen komplizierter zu implementieren.

%TODO

%Jeder Parameter- und Rückgabetyp wird daraufhin untersucht, wie viele Elemente mindestens vorliegen
%müssen, damit man es in ein SIMD-Register laden kann. Diese Anzahl heißt \emph{SIMD-Breite}
%($W_{simd})$. Die Breite des Registers heißt \emph{Register-Breite} ($W_{reg}$). Beide Größen werden
%in Byte gemessen. Der \texttt{sizeof} Operator liefert die Größe eines Typen in Bytes. Es wird
%angenommen, dass alle Werte Zweierpotenzen sind.

%Um die SIMD-Breite eines Datentypen $T$ zu ermitteln, wird folgendes Verfahren benutzt:

%\begin{itemize}

    %\item Ist $T$ ein atomarer Datentyp, so ist $W_{simd} = \frac{W_{reg}}{\texttt{sizeof}(T)}$.

    %\item Ist $T$ ein zusammengesetzter Datentyp, so wende diese Verfahren rekursiv auf die
    %Aggregatstypen $A_i$ an und setze $W_{simd}$ auf das größte Teilergebnis.

%\end{itemize}

%Im Falle eines Typen bestehend aus einem Double (acht Bytes) und einem Word (zwei Bytes) ergibt sich
%im Falle von SSE (16 Byte-Register) eine SIMD-Breite von acht.

%Das Speicherlayout in einem SIMD-Container der Größe $size$, ergibt sich nun wie folgt: Jedes
%atomare Aggregat taucht $W_{simd}$-mal im Speicher auf. Dies wird $ceil(size/W_{simd})$-mal
%wiederholt.  Ist $size$ nicht durch $W_{simd}$ teilbar, müssen am Ende Dummy-Werte hinzugefügt
%werden. Ist die Anzahl zur Compilezeit nicht bekannt, kann die interne Größe auch einfauch pauschal
%um $W_{simd}-1$ erhöht werden. 

%Nun müssen noch die SIMD-Funktionen transformiert werden. Ausgehend vom Origimal haben alle
%Variablen und Parameter in der SIMD-Version einen Vektor des Origimaltyps der Größe $W_{simd}$. In
%der Registerzuteilung muss ggf. darauf geachtet werden, dass evt. mehr als ein SIMD-Register
%benötigt wird.

\end{document}
